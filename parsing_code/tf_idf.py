# convert term frequency file, generated by countFreq.py, to tf-idf

import sparsity
import timeit 
import math


def tf_idf(termID, freq, nDocs, termFreqHash):
	tf = math.log(freq, 10) # log of term frequency 
	tf = 1 + tf # add 1 smoothing to account for log(1) = 0
	idf = nDocs/float(termFreqHash[termID]) # inverse doc frequency
	idf = math.log(idf, 10) # log of idf 
	return round(tf*idf, 3) # arbitrarily run to 3 numbers after desimal place  


def freq_to_tfidf(termFreqFile, termFreqHash, nDocs, tfidf_out):
	with open(termFreqFile) as f, open(tfidf_out, 'w') as out:
		for line in f:
			if line != "\n": # paper has abstract with terms 
				pairs = line.strip().split('\t')
				line = ""
				for pair in pairs:
					[termId, freq] = pair.split(' ')
					score = tf_idf(int(termId), int(freq), nDocs, termFreqHash)
					line += ' '.join([termId, str(score)]) + '\t' 
			line = line.strip() # strip out the last tab 
			out.write(line+'\n') 	

def main():
	t = timeit.default_timer()
	termFreqFile = "../info_data/abstracts_term_freq.txt"
	termFreqHash = sparsity.buildTermFreqHash(termFreqFile)
	print "\n Time took to build term freq hash: ", timeit.default_timer() - t

	tfidf_out = "../info_data/abstracts_tf_idf.txt"
	nDocs = 1516
	freq_to_tfidf(termFreqFile, termFreqHash, nDocs, tfidf_out)
	


if __name__ == '__main__':
	main()